# Docker Compose 配置
#
# 使用方式:
#   多容器模式: docker compose up -d
#   单容器模式: docker compose -f docker-compose.yml -f docker-compose.single.yml up -d

services:
  gateway:
    build:
      context: .
      target: gateway
      cache_from:
        - type=local,src=/tmp/.buildx-cache
    image: dbmanager/gateway:latest
    ports:
      - "8080:8080"
    environment:
      - SERVER_HOST=0.0.0.0
      - SERVER_PORT=8080
      - CONNECTION_SERVICE_URL=http://connection-service:8081
      - QUERY_SERVICE_URL=http://query-service:8082
      - AI_SERVICE_URL=http://ai-service:8083
      - RUST_LOG=info
    depends_on:
      connection-service:
        condition: service_started
      query-service:
        condition: service_started
      ai-service:
        condition: service_started
    networks:
      - dbmanager
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 32M
    restart: unless-stopped

  connection-service:
    build:
      context: .
      target: connection-service
    image: dbmanager/connection-service:latest
    ports:
      - "8081:8081"
    environment:
      - SERVER_HOST=0.0.0.0
      - SERVER_PORT=8081
      - RUST_LOG=info
      - MAX_CONNECTIONS=10
      - CONNECT_TIMEOUT=30
    networks:
      - dbmanager
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 64M
    restart: unless-stopped

  query-service:
    build:
      context: .
      target: query-service
    image: dbmanager/query-service:latest
    ports:
      - "8082:8082"
    environment:
      - SERVER_HOST=0.0.0.0
      - SERVER_PORT=8082
      - CONNECTION_SERVICE_URL=http://connection-service:8081
      - RUST_LOG=info
    depends_on:
      - connection-service
    networks:
      - dbmanager
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 64M
    restart: unless-stopped

  ai-service:
    build:
      context: .
      target: ai-service
    image: dbmanager/ai-service:latest
    ports:
      - "8083:8083"
    environment:
      - SERVER_HOST=0.0.0.0
      - SERVER_PORT=8083
      - CONNECTION_SERVICE_URL=http://connection-service:8081
      - QUERY_SERVICE_URL=http://query-service:8082
      - LLM_BASE_URL=${LLM_BASE_URL:-https://api.openai.com/v1}
      - LLM_API_KEY=${LLM_API_KEY:-}
      - LLM_DEFAULT_MODEL=${LLM_DEFAULT_MODEL:-gpt-4o-mini}
      - LLM_HIGH_PRECISION_MODEL=${LLM_HIGH_PRECISION_MODEL:-gpt-4o}
      - RUST_LOG=info
    depends_on:
      - connection-service
      - query-service
    networks:
      - dbmanager
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 64M
    restart: unless-stopped

networks:
  dbmanager:
    driver: bridge
